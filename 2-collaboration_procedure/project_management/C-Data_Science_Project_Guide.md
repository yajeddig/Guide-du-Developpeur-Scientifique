# Démarche de Déroulement d'un Projet en Data Science

La méthodologie en Data Science suit une approche structurée pour répondre aux questions commerciales à travers l'analyse de données. Elle se décompose en plusieurs étapes clés, chacune ayant son propre objectif et ses actions spécifiques.

## 1. Compréhension du Domaine (Business Understanding)

### Objectif : Comprendre la Question

La première étape de la méthodologie en Data Science consiste à clarifier et à atteindre une compréhension approfondie du domaine commercial.

- **Définir :** Clarifier la question posée est crucial car elle guide toute l'approche analytique.
- **Comprendre :** Comprendre l'objectif de la personne posant la question est essentiel pour établir une question bien définie.
- **Objectifs :** Les objectifs qui soutiennent le but doivent être identifiés pour prioriser et planifier la résolution des problèmes. **À ce stade, il est crucial de définir des indicateurs et des objectifs quantifiables basés sur des mesures claires.** Cela permet de savoir précisément quand les objectifs sont atteints et d'éviter des cycles de travail sans fin.
- **Engagement :** L'engagement des différentes parties prenantes est essentiel pour déterminer les exigences et clarifier les questions.

## 2. Approche Analytique (Analytic Approach)

### Objectif : Déterminer l'Approche Appropriée

La deuxième étape consiste à sélectionner l'approche analytique la plus adaptée au contexte des exigences commerciales.

- **Modèle :** Identifier quels types de modèles et de patterns seront nécessaires pour répondre efficacement à la question posée.
- **Approche :** Différentes approches analytiques dans les données sont explorées pour répondre aux questions.
- **Types de Questions :** Des questions descriptives, diagnostiques, prédictives, et prescriptives sont adressées.
- **Apprentissage Automatique :** Les ordinateurs apprennent à prédire sans être explicitement programmés, révélant des patterns dans les données autrement inaccessibles.

## 3. Exigences et Collecte des Données (Data Requirement and Collection)

### Objectif : Collecter les Bonnes Données

Cette étape de la méthodologie en Data Science met en avant l'importance d'identifier, de sourcer, de comprendre, et de préparer les données nécessaires à l'analyse.

- **Exigences en Données :** L'exigence initiale de collecte de données est évaluée pour sa pertinence. Les exigences sont révisées en fonction de la disponibilité, de la qualité, et du contenu des données.
- **Collecte des Données :** Nécessite de connaître la source et où trouver les données nécessaires. Les décisions sont basées sur les données collectées.
- **Intégration des Données :** Les administrateurs de base de données extraient, préparent, et intègrent les sources de données. Les redondances sont éliminées pour assurer une compréhension des données.
- **Compréhension des Données :** L'utilisation des statistiques et de la visualisation pour comprendre les données, identifier les écarts, planifier les actions correctives et préparer les prochaines étapes de l'analyse.

## 4. Compréhension et Préparation des Données (Data Understanding and Preparation)

### Objectif : Compréhension des Données et Évaluation Itérative

Le rôle significatif de l'évaluation des données et des techniques de préparation efficaces pour atteindre des résultats analytiques réussis.

- **Importance de la Compréhension :** La compréhension des données commence avec une exploration initiale pour évaluer leur qualité. Ce processus est itératif tout au long du projet.
- **Évaluation et Itération :** L'évaluation des données identifie les problèmes à résoudre dans le cycle de vie des données. Une compréhension approfondie se développe avec chaque itération.
- **Préparation des Données :** Comprend la transformation des données en un format utilisable, comme le nettoyage, la mise en forme, et la normalisation des valeurs.
- **Efficacité et Qualité :** Priorisation de l'ingénierie des fonctionnalités et des processus automatisés pour s'assurer que les données prêtes sont de haute qualité et optimisées pour les résultats analytiques.

## 5. De la Modélisation à l'Évaluation (Modeling to Evaluation)

### Objectif : Révéler le Processus de Modélisation et Évaluer la Performance

La modélisation et l'évaluation jouent un rôle clé dans la mise en forme des résultats analytiques et dans le raffinement des stratégies de résolution de problèmes.

- **Modélisation des Données :** Les algorithmes sont utilisés pour caractériser les données et choisir les approches de modélisation. Les modèles sont créés en fonction de l'analyse des données disponibles.
- **Ensemble d'Entraînement et Calibration :** L'ensemble d'entraînement est utilisé pour expérimenter avec les algorithmes, en sélectionnant les paramètres appropriés pour optimiser les résultats basés sur les données du projet.
- **Évaluation des Modèles :** L'évaluation des modèles est une étape essentielle pour affiner les modèles et construire des solutions de haute qualité alignées sur les besoins commerciaux. **Les indicateurs quantifiables définis précédemment sont ici utilisés pour mesurer la performance des modèles, permettant de savoir quand un modèle est suffisamment bon ou si des ajustements sont nécessaires.**
- **Mesures Diagnostiques :** Les mesures diagnostiques fournissent des interprétations des tests des modèles, y compris les mesures ROC, AUC et autres, pour évaluer la performance de la solution.

## 6. Du Déploiement au Retour d'Information (From Deployment to Feedback)

### Objectif : Déploiement en Conditions Réelles, Retour d'Information et Redéploiement

Maximiser l'impact de la Data Science à travers l'engagement des parties prenantes et le raffinement itératif.

- **Engagement des Parties Prenantes :** Il est important d'impliquer toutes les parties concernées dans le processus de déploiement pour garantir que la solution développée répond aux attentes et aux besoins spécifiques.
- **Déploiement et Retour d'Information :** Déployer le projet avec des tests en temps réel pour vérifier la fonctionnalité, tout en collectant des retours d'information pour améliorer la solution.
- **Processus Itératif :** La méthodologie CRISP-DM est affinée à chaque étape pour améliorer continuellement le projet. Des boucles de rétroaction sont mises en place pour permettre des ajustements rapides en fonction des nouvelles données.
- **Amélioration et Redéploiement :** Intégration des retours pour affiner et redéployer la solution, en apportant des actions correctives et en ajustant les paramètres pour améliorer les résultats, en particulier face à des défis complexes ou imprévus.

## CRISP-DM c'est quoi ?

La méthodologie CRISP-DM (Cross-Industry Standard Process for Data Mining) est une norme largement utilisée pour le développement de projets de data mining et de Data Science. Elle offre un cadre structuré pour mener des projets en suivant six étapes clés :

1. **Compréhension du Domaine (Business Understanding) :** Identification des objectifs commerciaux et des besoins du projet.
2. **Compréhension des Données (Data Understanding) :** Collecte initiale des données, familiarisation avec celles-ci, identification des problèmes de qualité, et détection des premières insights.
3. **Préparation des Données (Data Preparation) :** Sélection, nettoyage, transformation, et formatage des données pour les adapter aux outils d'analyse.
4. **Modélisation (Modeling) :** Application de techniques de modélisation pour créer des modèles prédictifs en fonction des données préparées.
5. **Évaluation (Evaluation) :** Validation du modèle pour s'assurer qu'il atteint les objectifs commerciaux identifiés lors de la première étape.
6. **Déploiement (Deployment) :** Mise en production du modèle, ce qui peut inclure l'intégration dans des systèmes d'information, le suivi des performances, et le retour d'information continu pour améliorer le modèle.

CRISP-DM est itératif, permettant de revenir en arrière et de répéter certaines étapes pour affiner les résultats en fonction des découvertes et des retours obtenus tout au long du projet.